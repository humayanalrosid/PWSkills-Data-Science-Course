{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web scraping is the process of extracting data from websites using automated software or tools. In this method, text, images, links, and other structured data are extracted from a website's HTML code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web scraping is used for various purposes, including:\n",
    "\n",
    "* We use it to collects data on competitors, product features, and customer reviews to gain insights into the market and make informed decisions.\n",
    "\n",
    "* We can collect large amounts of data from various sources for data analysis, data mining, and machine learning.\n",
    "\n",
    "* We collect contact information about customers, such as mobile numbers, email addresses and social media profiles, to generate leads for sales and marketing purposes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I mentioned three areas where web scraping is used:\n",
    "\n",
    "* E-commerce: It is used to collect product data, pricing information, customer reviews, and other related information from e-commerce websites such as Amazon, eBay.\n",
    "\n",
    "* Social Media: It is used to collect data such as user profiles, posts, comments, and other related data from social media platforms such as Facebook, Twitter, and LinkedIn.\n",
    "\n",
    "* Real Estate: It is used to collect data on property listings, prices, location, and other related information from real estate websites such as Zillow, Redfin, and Trulia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web scraping uses several techniques, including:\n",
    "\n",
    "* Manual Scraping: We can manually copy and paste data from websites into a spreadsheet or database. But this method is not ideal for large-scale data extraction.\n",
    "\n",
    "* Web Scraping Tools: We can use web scraping tools or software to automatically get data from websites. These tools use web crawling to navigate through websites. It extracts data based on rules.\n",
    "\n",
    "* APIs: APIs provide a structured way to access website data. Many websites offer APIs to view their data. It can be used for web scraping.\n",
    "\n",
    "* Parsing HTML: We can extract data from HTML code on a website. This method includes identifying the HTML elements that hold the data and using programming languages such as Python or JavaScript to extract the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful Soup is a popular Python library for web scraping. It extracts data from HTML and XML files.\n",
    "\n",
    "Beautiful Soup is used for web scraping because:\n",
    "\n",
    "* Beautiful Soup parses HTML and XML files using an easy-to-use API. It allows us to quickly extract data from websites without writing complex code.\n",
    "\n",
    "* It is difficult to extract data from HTML or XML documents since they are complex and inconsistent. Beautiful Soup can handle complex HTML or XML codes.\n",
    "\n",
    "* It supports multiple parsers, including lxml, html5lib, and html.parser. It's easy to switch between parsers based on the project.\n",
    "\n",
    "* I can use regular expressions to search and extract data from HTML and XML documents.\n",
    "\n",
    "* It is an open-source library, which means it is free to use and can be modified and distributed by anyone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flask is a lightweight and flexible Python web framework used in this web scraping project for several reasons:\n",
    "\n",
    "* Flask offers a simple and intuitive way to define URL routes for handling incoming requests. \n",
    "\n",
    "* It provides a built-in templating engine that allows developers to create HTML pages dynamically based on web scraping data. \n",
    "\n",
    "* It is a lightweight framework that does not require much setup or configuration. \n",
    "\n",
    "* It can be easily integrated with other Python libraries such as Beautiful Soup, Requests, and Pandas, which are frequently used in web scraping projects.\n",
    "\n",
    "* It can be easily deployed on various hosting platforms, such as Heroku or AWS, making it easy to install and scale a web scraping project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, Code Pipeline and Elastic Beanstalk are used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Pipeline\n",
    "\n",
    "We can connect AWS code pipeline to Github before deployment. It allos us to build, test, and deploy our code every time a change is made to the repository. This ensures our software is always up-to-date and bug-free."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elastic Beanstalk\n",
    "\n",
    "AWS Elastic Beanstalk makes it easy to deploy and scale web applications. The service automatically scales, distributes and manages capacity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
